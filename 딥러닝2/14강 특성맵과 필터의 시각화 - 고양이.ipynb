{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e98313",
   "metadata": {
    "id": "f0e98313"
   },
   "source": [
    "# 특성맵(feature map) 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7d7dc",
   "metadata": {
    "id": "43c7d7dc"
   },
   "source": [
    "Xception 모델을 불러오겠습니다.  \n",
    "파라미터들은 ImageNet으로 이미 훈련되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f759319",
   "metadata": {
    "id": "3f759319"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.applications.xception.Xception()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb255008",
   "metadata": {
    "id": "cb255008"
   },
   "source": [
    "고양이 이미지를 다운받고 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcb3d7",
   "metadata": {
    "id": "f0dcb3d7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "\n",
    "img_path = keras.utils.get_file(\n",
    "    fname=\"cat.jpg\",\n",
    "    origin=\"https://img-datasets.s3.amazonaws.com/cat.jpg\")\n",
    "img = image.imread(img_path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bdf9",
   "metadata": {
    "id": "5304bdf9"
   },
   "source": [
    "Xception의 입력해상도 299$\\times$299로 변환하고 이걸 다시 numpy array형으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2afc1",
   "metadata": {
    "id": "55a2afc1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "img = tf.image.resize(img,(299,299))\n",
    "img = keras.utils.img_to_array(img)\n",
    "\n",
    "plt.imshow(img/255)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2e249",
   "metadata": {
    "id": "d4f2e249"
   },
   "source": [
    "Xception이 예측한 5가지 클래스가 모두 고양이 품종입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89706446",
   "metadata": {
    "id": "89706446"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import gdown, zipfile, os\n",
    "\n",
    "if not os.path.isfile('VGG16_test.zip'):\n",
    "    gdown.download(id='1K46V-TnwB8EWuk0RGE-oloVs9HfHRbGp', output='imagenet_classes.txt')\n",
    "\n",
    "with open('imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "img = tf.expand_dims(img,axis=0)\n",
    "out=model(tf.keras.applications.xception.preprocess_input(img))\n",
    "\n",
    "top_5 = np.argsort(-out[0])[:5]\n",
    "for idx in top_5:\n",
    "    print(f\"{labels[idx]} : {out[0,idx]*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58bb19",
   "metadata": {
    "id": "ff58bb19"
   },
   "source": [
    "`isinstance`는 layer가 클래스 `Conv2D` 또는 클래스 `SeparableConv2D`의 인스턴스면 `True`를 리턴하고 그렇지 않으면 `False`를 리턴합니다.  \n",
    "합성곱층에서 출력되는 특성맵들을 리스트로 묶습니다.  \n",
    "함수형 API로 이미지가 입력되면 특성맵(feature map)들의 리스트가 출력되는 다중 출력 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a95ae",
   "metadata": {
    "id": "047a95ae"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D\n",
    "\n",
    "layer_outputs = []\n",
    "layer_names = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, (Conv2D, SeparableConv2D)):\n",
    "        layer_outputs.append(layer.output)\n",
    "        layer_names.append(layer.name)\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987713b",
   "metadata": {
    "id": "d987713b"
   },
   "source": [
    "[tf.keras.applications.xception.preprocess_input](https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/preprocess_input)는 입력 데이터를 전처리한 후 덮어쓰기 때문에 다시 적용하면 안됩니다.  \n",
    "합성곱층에서 출력되는 특성맵들의 해상도와 채널 깊이수입니다.  \n",
    "max pooling층을 통과할때마다 해상도가 절반씩 줄어듭니다.  \n",
    "합성곱층 필터가 2배 증가할때는 채널의 깊이도 2배 늘어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63f669",
   "metadata": {
    "id": "0f63f669"
   },
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img)\n",
    "\n",
    "for i in range(len(activations)):\n",
    "    print(activations[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9163f52",
   "metadata": {
    "id": "b9163f52"
   },
   "source": [
    "2번째 합성곱층이 출력하는 피처맵 64장중 앞 25장입니다.\n",
    "- (1,1)번째 필터는 경계선에 반응하는 듯합니다.\n",
    "- (1,2)번째 필터는 고양이의 흰 색깔에 반응하는 듯합니다.  \n",
    "- (1,3)번째 필터는 세로 경계선에 반응하는 듯합니다.  \n",
    "- (2,2)번째 필터는 가로 경계선에 반응하는 듯합니다.  \n",
    "- (5,4)번째 필터는 고양이의 파란 눈에 반응하는 듯합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3423c6",
   "metadata": {
    "id": "2e3423c6"
   },
   "outputs": [],
   "source": [
    "n=1\n",
    "\n",
    "print(activations[n][0,:,:,:].shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(activations[n][0,:,:,i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8909720",
   "metadata": {
    "id": "a8909720"
   },
   "source": [
    "8번째 합성곱층이 출력하는 피처맵 256장중 앞 25장입니다.  \n",
    "max pooling층을 두번 거치며 해상도가 1/4로 줄었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187fc98",
   "metadata": {
    "id": "8187fc98"
   },
   "outputs": [],
   "source": [
    "n=7\n",
    "\n",
    "print(activations[n][0,:,:,:].shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(activations[n][0,:,:,i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df8a4e",
   "metadata": {
    "id": "f2df8a4e"
   },
   "source": [
    "11번째 합성곱층이 출력하는 피처맵 728장중 앞 25장입니다.  \n",
    "max pooling층을 거치며 해상도가 절반으로 줄었습니다.  \n",
    "이제는 이미지 소스가 고양이였다는걸 알아보기 힘듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e61fc",
   "metadata": {
    "id": "ba5e61fc"
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "\n",
    "print(activations[n][0,:,:,:].shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(activations[n][0,:,:,i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb89276",
   "metadata": {
    "id": "dfb89276"
   },
   "source": [
    "마지막 합성곱층이 출력하는 피처맵 2048장중 앞 25장입니다.  \n",
    "max pooling층을 거치며 해상도가 절반으로 줄었습니다.  \n",
    "이제는 전혀 알아볼수가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8485d",
   "metadata": {
    "id": "0de8485d"
   },
   "outputs": [],
   "source": [
    "n=-1\n",
    "\n",
    "print(activations[n][0,:,:,:].shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(activations[n][0,:,:,i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec3b6a",
   "metadata": {
    "id": "66ec3b6a"
   },
   "source": [
    "# 필터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f11a8b",
   "metadata": {
    "id": "81f11a8b"
   },
   "source": [
    "첫번째 합성곱층에는 32개의 3$\\times$3$\\times$3 필터가 있습니다.  \n",
    "앞 25장의 첫번째 채널을 시각화한 이미지들입니다.  \n",
    "무슨 의미인지 모르겠네요.  \n",
    "사실 다른 층의 필터들도 출력해보면 이해할수 없긴 마찬가지입니다.  \n",
    "이번 섹션의 목표는 필터마다 이해가능한 이미지를 대응시키는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0acb61",
   "metadata": {
    "id": "3f0acb61"
   },
   "outputs": [],
   "source": [
    "layer = model.get_layer(name=\"block1_conv1\")\n",
    "\n",
    "print(layer.weights[0].shape)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(np.array(layer.weights[0])[:,:,0,i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d641de",
   "metadata": {
    "id": "74d641de"
   },
   "source": [
    "입력해상도를 299$\\times$299에서 200$\\times$200으로 바꾸기 위해 Xception을 다시 불러오겠습니다.  \n",
    "`include_top=False`로 설정하면 입력해상도를 변경할 수 있습니다.  \n",
    "299$\\times$299로도 이번 섹션의 목적을 달성할 수 있지만 출력해보면 200$\\times$200이 더 그럴듯해 보입니다.  \n",
    "이미지가 입력되면 특성맵들의 리스트가 출력되는 다중 출력 모델을 다시 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd205597",
   "metadata": {
    "id": "cd205597"
   },
   "outputs": [],
   "source": [
    "model = keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)\n",
    "\n",
    "layer_outputs = []\n",
    "layer_names = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, (Conv2D, SeparableConv2D)):\n",
    "        layer_outputs.append(layer.output)\n",
    "        layer_names.append(layer.name)\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273718a",
   "metadata": {
    "id": "0273718a"
   },
   "source": [
    "필터마다 어떤 이미지를 대응시키는 함수 `visualize_filter`를 정의하겠습니다.  \n",
    "`visualize_filter`를 블럭별로 해석하면 다음과 같습니다.\n",
    "- 200$\\times$200 해상도의 컬러 이미지를 랜덤하게 만듭니다. 픽셀값은 0.4~0.6사이에서 균등분포를 따릅니다.\n",
    "- 이미지를 입력했을 때 `conv_index`번째 합성곱층에서 출력하는 특성맵들을 생각합니다. 그중에서 `filter_index`번째 필터에 대응하는 특성맵을 뽑아내고 주변 2픽셀을 삭제한후 모든 픽셀값들을 평균하겠습니다. 함수 $F$는 이 대응관계로 정의되는 함수입니다. 자동미분을 하기위해 `GradientTape`안에서 정의하고 image는 텐서플로우 변수형으로 바꿔줍니다.\n",
    "- 함수 $F$를 입력 이미지로 미분해서 그레디언트를 구합니다. 그리고 크기 1로 노멀라이즈 합니다. 학습률 10으로 30번 경사상승법을 적용합니다. 함수 $F$의 최대점을 찾아가는데 목적입니다. \n",
    "- 텐터플로우 변수형은 수정이 안되기 때문에 일단 numpy array형으로 바꿉니다. 평균 0, 표준편차 1로 노멀라이즈한 후 다시 평균 128, 표준편차 64로 바꿔줍니다. 0과 255를 벗어나는 픽셀은 모두 0으로 클리핑한 후 정수형으로 바꿔줍니다. 가장자리 25픽셀들은 삭제합니다.\n",
    "\n",
    "함수 $F$의 최대점은 `conv_index`번째 합성곱층의 `filter_index`번째 필터에 가장 적극적으로 반응하는 이미지라고 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107af6a6",
   "metadata": {
    "id": "107af6a6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def visualize_filter(conv_index, filter_index):\n",
    "    img = tf.random.uniform(minval=0.4, maxval=0.6, shape=(1, 200, 200, 3))\n",
    "    keras.applications.xception.preprocess_input(img)\n",
    "    \n",
    "    for i in range(30):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(img)\n",
    "            activations = activation_model(img)\n",
    "            activation = activations[conv_index]\n",
    "            F = tf.reduce_mean(activation[:, 2:-2, 2:-2, filter_index])\n",
    "\n",
    "        grads = tape.gradient(F, img)\n",
    "        grads = tf.math.l2_normalize(grads)\n",
    "        img += 10 * grads\n",
    "    \n",
    "    img = img[0].numpy()\n",
    "    img -= img.mean()\n",
    "    img /= img.std()\n",
    "    img *= 64\n",
    "    img += 128\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "    img = img[25:-25, 25:-25, :]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65821cc4",
   "metadata": {
    "id": "65821cc4"
   },
   "source": [
    "첫번째 합성곱층의 32개 필터중 앞 25장에 가장 적극적으로 반응하는 입력 이미지들입니다.  \n",
    "색깔 또는 매우 단순한 기하적 패턴에 반응합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa34d2",
   "metadata": {
    "id": "2faa34d2"
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "\n",
    "print(activations[n].shape[-1])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(visualize_filter(n,i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb46c36",
   "metadata": {
    "id": "bfb46c36"
   },
   "source": [
    "세번째 합성곱층의 128개 필터중 앞 25장에 가장 적극적으로 반응하는 입력 이미지들입니다.  \n",
    "세로선, 가로선, 사선에 반응하는 듯 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d355c",
   "metadata": {
    "id": "049d355c"
   },
   "outputs": [],
   "source": [
    "n=2\n",
    "\n",
    "print(activations[n].shape[-1])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(visualize_filter(n,i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e30768",
   "metadata": {
    "id": "b7e30768"
   },
   "source": [
    "9번째 합성곱층의 728개 필터중 앞 25장에 가장 적극적으로 반응하는 입력 이미지들입니다.  \n",
    "복잡한 패턴들에 반응하기 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe3af3",
   "metadata": {
    "id": "c9fe3af3"
   },
   "outputs": [],
   "source": [
    "n=8\n",
    "\n",
    "print(activations[n].shape[-1])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(visualize_filter(n,i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686d215",
   "metadata": {
    "id": "5686d215"
   },
   "source": [
    "14번째 합성곱층의 728개 필터중 앞 25장에 가장 적극적으로 반응하는 입력 이미지들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0e4fd",
   "metadata": {
    "id": "7fa0e4fd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=13\n",
    "\n",
    "print(activations[n].shape[-1])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(visualize_filter(n,i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28aafb3",
   "metadata": {
    "id": "e28aafb3"
   },
   "source": [
    "21번째 합성곱층의 728개 필터중 앞 25장에 가장 적극적으로 반응하는 입력 이미지들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55ae45",
   "metadata": {
    "id": "5e55ae45"
   },
   "outputs": [],
   "source": [
    "n=20\n",
    "\n",
    "print(activations[n].shape[-1])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(visualize_filter(n,i))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
